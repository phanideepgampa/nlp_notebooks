{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, non deep learning classification models are trained on linguistic features of the data like POS, Named Entity, Syntactic Dependency etc.\n",
    "- The best accuracy on the test set is **0.87** using Linear SVC. The accuracy using bert is **0.978**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set seed\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(2020) # for reproducibility of random modules if used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = open('data/train_5500.txt', 'r+')\n",
    "f_test = open('data/TREC_10.txt', 'r+')\n",
    "\n",
    "train = pd.DataFrame(f_train.readlines(), columns = ['Question'])\n",
    "test = pd.DataFrame(f_test.readlines(), columns = ['Question'])\n",
    "\n",
    "train['QType'] = train.Question.apply(lambda x: x.split(' ', 1)[0])\n",
    "train['Question'] = train.Question.apply(lambda x: x.split(' ', 1)[1])\n",
    "train['QType-Coarse'] = train.QType.apply(lambda x: x.split(':')[0])\n",
    "train['QType-Fine'] = train.QType.apply(lambda x: x.split(':')[1])\n",
    "test['QType'] = test.Question.apply(lambda x: x.split(' ', 1)[0])\n",
    "test['Question'] = test.Question.apply(lambda x: x.split(' ', 1)[1])\n",
    "test['QType-Coarse'] = test.QType.apply(lambda x: x.split(':')[0])\n",
    "test['QType-Fine'] = test.QType.apply(lambda x: x.split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>QType</th>\n",
       "      <th>QType-Coarse</th>\n",
       "      <th>QType-Fine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "      <td>DESC:manner</td>\n",
       "      <td>DESC</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What films featured the character Popeye Doyle...</td>\n",
       "      <td>ENTY:cremat</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>cremat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "      <td>DESC:manner</td>\n",
       "      <td>DESC</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>ENTY:animal</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the full form of .com ?\\n</td>\n",
       "      <td>ABBR:exp</td>\n",
       "      <td>ABBR</td>\n",
       "      <td>exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question        QType  \\\n",
       "0  How did serfdom develop in and then leave Russ...  DESC:manner   \n",
       "1  What films featured the character Popeye Doyle...  ENTY:cremat   \n",
       "2  How can I find a list of celebrities ' real na...  DESC:manner   \n",
       "3  What fowl grabs the spotlight after the Chines...  ENTY:animal   \n",
       "4                  What is the full form of .com ?\\n     ABBR:exp   \n",
       "\n",
       "  QType-Coarse QType-Fine  \n",
       "0         DESC     manner  \n",
       "1         ENTY     cremat  \n",
       "2         DESC     manner  \n",
       "3         ENTY     animal  \n",
       "4         ABBR        exp  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>QType</th>\n",
       "      <th>QType-Coarse</th>\n",
       "      <th>QType-Fine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did serfdom develop in and then leave Russ...</td>\n",
       "      <td>DESC:manner</td>\n",
       "      <td>1</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What films featured the character Popeye Doyle...</td>\n",
       "      <td>ENTY:cremat</td>\n",
       "      <td>2</td>\n",
       "      <td>cremat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I find a list of celebrities ' real na...</td>\n",
       "      <td>DESC:manner</td>\n",
       "      <td>1</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
       "      <td>ENTY:animal</td>\n",
       "      <td>2</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the full form of .com ?\\n</td>\n",
       "      <td>ABBR:exp</td>\n",
       "      <td>0</td>\n",
       "      <td>exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question        QType  \\\n",
       "0  How did serfdom develop in and then leave Russ...  DESC:manner   \n",
       "1  What films featured the character Popeye Doyle...  ENTY:cremat   \n",
       "2  How can I find a list of celebrities ' real na...  DESC:manner   \n",
       "3  What fowl grabs the spotlight after the Chines...  ENTY:animal   \n",
       "4                  What is the full form of .com ?\\n     ABBR:exp   \n",
       "\n",
       "   QType-Coarse QType-Fine  \n",
       "0             1     manner  \n",
       "1             2     cremat  \n",
       "2             1     manner  \n",
       "3             2     animal  \n",
       "4             0        exp  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(pd.Series(train['QType-Coarse'].tolist() + test['QType-Coarse'].tolist()).values)\n",
    "train['QType-Coarse'] = le.transform(train['QType-Coarse'].values)\n",
    "test['QType-Coarse'] = le.transform(test['QType-Coarse'].values)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mila/g/gampapha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/mila/g/gampapha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re, nltk\n",
    "import gensim\n",
    "import codecs\n",
    "import spacy \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, average_precision_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.internals import find_jars_within_path\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corpus = pd.Series(train.Question.tolist() + test.Question.tolist()).astype(str)\n",
    "dot_words = []\n",
    "for row in all_corpus:\n",
    "    for word in row.split():\n",
    "        if '.' in word and len(word)>2:\n",
    "            dot_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'.com': 1,\n",
       "         'St.': 17,\n",
       "         'U.S.': 151,\n",
       "         'J.R.R.': 2,\n",
       "         'T.V.': 1,\n",
       "         'S.O.S.': 1,\n",
       "         'No.1': 1,\n",
       "         'Answers.com': 5,\n",
       "         'U.K.': 2,\n",
       "         'Mrs.': 6,\n",
       "         'G.M.T.': 1,\n",
       "         'www.answers.com': 1,\n",
       "         'A.G.': 1,\n",
       "         '.dbf': 1,\n",
       "         'www.questions.com': 1,\n",
       "         'KnowPost.com': 1,\n",
       "         'L.A.': 4,\n",
       "         'W.B.': 1,\n",
       "         'D.B.': 1,\n",
       "         '42.3': 1,\n",
       "         'Dr.': 4,\n",
       "         'Rev.': 1,\n",
       "         'Jan.': 1,\n",
       "         'Jr.': 4,\n",
       "         'No.': 3,\n",
       "         'Mr.': 6,\n",
       "         'Ms.': 2,\n",
       "         'Inc.': 3,\n",
       "         'cwt.': 1,\n",
       "         'U.S.A.': 3,\n",
       "         'etc.': 3,\n",
       "         'question..': 1,\n",
       "         'D.C.': 6,\n",
       "         'N.M': 1,\n",
       "         'e.g.': 2,\n",
       "         '...the': 1,\n",
       "         'q.i.d': 1,\n",
       "         'aol.com': 1,\n",
       "         'yahoo.com': 1,\n",
       "         'J.D.': 1,\n",
       "         'LL.M.': 1,\n",
       "         'U.S.S.R.': 1,\n",
       "         'creativity.': 1,\n",
       "         'a.m.': 1,\n",
       "         'p.m.': 3,\n",
       "         '...': 1,\n",
       "         'king..': 1,\n",
       "         'answers.com': 1,\n",
       "         'U.S.-based': 1,\n",
       "         'C.C.': 1,\n",
       "         'year..': 1,\n",
       "         'P.T.': 2,\n",
       "         'name..': 1,\n",
       "         'swift.': 1,\n",
       "         'v.9': 1,\n",
       "         'U.S': 1,\n",
       "         'most...subversive': 1,\n",
       "         'Bros.': 2,\n",
       "         'W.C.': 4,\n",
       "         'U.S.A': 2,\n",
       "         '1.76': 1,\n",
       "         'D.A.': 1,\n",
       "         '5.9': 1,\n",
       "         'O.J.': 1,\n",
       "         '2.5': 1,\n",
       "         'L.L.': 1,\n",
       "         'T.S.': 2,\n",
       "         '.tbk': 1,\n",
       "         'cc.': 1,\n",
       "         'B.Y.O.B.': 1,\n",
       "         'vs.': 3,\n",
       "         'D.H.': 1,\n",
       "         'discontent..': 1,\n",
       "         'R.E.M.': 2,\n",
       "         'H.G.': 1,\n",
       "         'Mt.': 1,\n",
       "         'Sen.': 1,\n",
       "         'J.F.K.': 1,\n",
       "         'I.V.': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(dot_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(corpus, keep_list):\n",
    "    '''\n",
    "    Function to keep only alphabets, digits and certain words (punctuations, qmarks, tabs etc. removed)\n",
    "    \n",
    "    '''\n",
    "    cleaned_corpus = pd.Series()\n",
    "    for row in corpus:\n",
    "        qs = []\n",
    "        for word in row.split():\n",
    "            if word not in keep_list:\n",
    "                p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n",
    "                p1 = p1.lower()\n",
    "                qs.append(p1)\n",
    "            else : qs.append(word)\n",
    "        cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs)))\n",
    "    return cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-40fe29d3c095>:6: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  cleaned_corpus = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "all_corpus = pd.Series(train.Question.tolist() + test.Question.tolist()).astype(str)\n",
    "common_dot_words = ['U.S.', 'St.', 'Mr.', 'Mrs.', 'D.C.']   #including most frequent dot words\n",
    "all_corpus = text_clean(all_corpus,common_dot_words)\n",
    "wh_words = ['who', 'what', 'when', 'why', 'how', 'which', 'where', 'whom']  # all of them are questions, so including these\n",
    "stop = set(stopwords.words('english'))\n",
    "for word in wh_words:\n",
    "    stop.remove(word)\n",
    "all_corpus = [[x for x in x.split() if x not in stop] for x in all_corpus]\n",
    "all_corpus = [' '.join(x) for x in all_corpus]\n",
    "train_corpus = all_corpus[0:train.shape[0]]\n",
    "test_corpus = all_corpus[train.shape[0]:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ner = []\n",
    "all_lemma = []\n",
    "all_tag = []\n",
    "all_dep = []\n",
    "all_shape = []\n",
    "for row in train_corpus:\n",
    "    doc = nlp(row)\n",
    "    present_lemma = []\n",
    "    present_tag = []\n",
    "    present_dep = []\n",
    "    present_shape = []\n",
    "    present_ner = []\n",
    "    #print(row)\n",
    "    for token in doc:\n",
    "        present_lemma.append(token.lemma_)\n",
    "        present_tag.append(token.tag_)\n",
    "        #print(present_tag)\n",
    "        present_dep.append(token.dep_)\n",
    "        present_shape.append(token.shape_)\n",
    "    all_lemma.append(\" \".join(present_lemma))\n",
    "    all_tag.append(\" \".join(present_tag))\n",
    "    all_dep.append(\" \".join(present_dep))\n",
    "    all_shape.append(\" \".join(present_shape))\n",
    "    for ent in doc.ents:\n",
    "        present_ner.append(ent.label_)\n",
    "    all_ner.append(\" \".join(present_ner))\n",
    "\n",
    "    \n",
    "count_vec_ner = CountVectorizer(ngram_range=(1, 2)).fit(all_ner)\n",
    "ner_ft = count_vec_ner.transform(all_ner)\n",
    "count_vec_lemma = CountVectorizer(ngram_range=(1, 2)).fit(all_lemma)\n",
    "lemma_ft = count_vec_lemma.transform(all_lemma)\n",
    "count_vec_tag = CountVectorizer(ngram_range=(1, 2)).fit(all_tag)\n",
    "tag_ft = count_vec_tag.transform(all_tag)\n",
    "count_vec_dep = CountVectorizer(ngram_range=(1, 2)).fit(all_dep)\n",
    "dep_ft = count_vec_dep.transform(all_dep)\n",
    "count_vec_shape = CountVectorizer(ngram_range=(1, 2)).fit(all_shape)\n",
    "shape_ft = count_vec_shape.transform(all_shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_ft_train = hstack([ner_ft, lemma_ft, tag_ft, dep_ft, shape_ft])\n",
    "\n",
    "x_all_ft_train= x_all_ft_train.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_ner = []\n",
    "all_test_lemma = []\n",
    "all_test_tag = []\n",
    "all_test_dep = []\n",
    "all_test_shape = []\n",
    "for row in test_corpus:\n",
    "    doc = nlp(row)\n",
    "    present_lemma = []\n",
    "    present_tag = []\n",
    "    present_dep = []\n",
    "    present_shape = []\n",
    "    present_ner = []\n",
    "    #print(row)\n",
    "    for token in doc:\n",
    "        present_lemma.append(token.lemma_)\n",
    "        present_tag.append(token.tag_)\n",
    "        #print(present_tag)\n",
    "        present_dep.append(token.dep_)\n",
    "        present_shape.append(token.shape_)\n",
    "    all_test_lemma.append(\" \".join(present_lemma))\n",
    "    all_test_tag.append(\" \".join(present_tag))\n",
    "    all_test_dep.append(\" \".join(present_dep))\n",
    "    all_test_shape.append(\" \".join(present_shape))\n",
    "    for ent in doc.ents:\n",
    "        present_ner.append(ent.label_)\n",
    "    all_test_ner.append(\" \".join(present_ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_test_ft = count_vec_ner.transform(all_test_ner)\n",
    "lemma_test_ft = count_vec_lemma.transform(all_test_lemma)\n",
    "tag_test_ft = count_vec_tag.transform(all_test_tag)\n",
    "dep_test_ft = count_vec_dep.transform(all_test_dep)\n",
    "shape_test_ft = count_vec_shape.transform(all_test_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_ft_test = hstack([ner_test_ft, lemma_test_ft, tag_test_ft, dep_test_ft, shape_test_ft]).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVC\n",
      "Training time: 1.393968s; Prediction time: 0.004478s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88         9\n",
      "           1       0.81      0.96      0.88       138\n",
      "           2       0.86      0.71      0.78        94\n",
      "           3       0.87      0.95      0.91        65\n",
      "           4       0.89      0.86      0.87        81\n",
      "           5       0.98      0.87      0.92       113\n",
      "\n",
      "    accuracy                           0.87       500\n",
      "   macro avg       0.90      0.86      0.87       500\n",
      "weighted avg       0.88      0.87      0.87       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/g/gampapha/.conda/envs/nlmatics/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "t0 = time.time()\n",
    "model.fit(x_all_ft_train, train['QType-Coarse'].values)\n",
    "t1 = time.time()\n",
    "y_pred = model.predict(x_all_ft_test)\n",
    "t2 = time.time()\n",
    "time_train = t1-t0\n",
    "time_predict = t2-t1\n",
    "\n",
    "\n",
    "print(\"Results for LinearSVC\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_train, time_predict))\n",
    "print(classification_report(test['QType-Coarse'].values, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVC\n",
      "Training time: 5.512071s; Prediction time: 0.013048s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88         9\n",
      "           1       0.81      0.99      0.89       138\n",
      "           2       0.76      0.72      0.74        94\n",
      "           3       0.86      0.88      0.87        65\n",
      "           4       0.86      0.80      0.83        81\n",
      "           5       0.98      0.81      0.89       113\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.88      0.83      0.85       500\n",
      "weighted avg       0.86      0.85      0.85       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "t0 = time.time()\n",
    "model.fit(x_all_ft_train, train['QType-Coarse'].values)\n",
    "t1 = time.time()\n",
    "y_pred = model.predict(x_all_ft_test)\n",
    "t2 = time.time()\n",
    "time_train = t1-t0\n",
    "time_predict = t2-t1\n",
    "\n",
    "\n",
    "print(\"Results for xgboost\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_train, time_predict))\n",
    "print(classification_report(test['QType-Coarse'].values, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier (non-linear kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVC\n",
      "Training time: 6.073678s; Prediction time: 0.387457s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.22      0.36         9\n",
      "           1       0.69      0.98      0.81       138\n",
      "           2       0.56      0.70      0.63        94\n",
      "           3       0.91      0.78      0.84        65\n",
      "           4       0.83      0.60      0.70        81\n",
      "           5       1.00      0.62      0.77       113\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.83      0.65      0.68       500\n",
      "weighted avg       0.79      0.75      0.74       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "t0 = time.time()\n",
    "model.fit(x_all_ft_train, train['QType-Coarse'].values)\n",
    "t1 = time.time()\n",
    "y_pred = model.predict(x_all_ft_test)\n",
    "t2 = time.time()\n",
    "time_train = t1-t0\n",
    "time_predict = t2-t1\n",
    "\n",
    "\n",
    "print(\"Results for SVC\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_train, time_predict))\n",
    "print(classification_report(test['QType-Coarse'].values, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlmatics)",
   "language": "python",
   "name": "nlmatics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
